## PHASE 1: BUILD COMPLETE AI USAGE LOGGING SYSTEM

### Overview
Every AI API call must be logged with full metadata. This is the foundation for:
- Cost tracking
- Usage limits
- Business analytics
- Billing system

---

### STEP 1: Database Schema

Create or update the `ai_usage_logs` table with this complete schema:
```sql
-- Drop and recreate for clean schema (or ALTER if data exists)
CREATE TABLE IF NOT EXISTS ai_usage_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- Who made the request
    user_id UUID REFERENCES users(id) ON DELETE SET NULL,
    user_email TEXT,  -- Store email for easy querying even if user deleted
    
    -- What service was used
    service_name TEXT NOT NULL,  -- 'xray_analyzer', 'cv_optimizer', 'questions_predictor', etc.
    service_action TEXT,  -- 'analyze', 'generate', 'optimize', etc.
    
    -- AI Provider details
    provider TEXT NOT NULL,  -- 'anthropic', 'google', 'openai'
    model TEXT NOT NULL,  -- 'claude-3-sonnet', 'gemini-2.0-flash', etc.
    
    -- Token usage (CRITICAL for cost calculation)
    input_tokens INTEGER NOT NULL DEFAULT 0,
    output_tokens INTEGER NOT NULL DEFAULT 0,
    total_tokens INTEGER NOT NULL DEFAULT 0,
    
    -- Cost calculation
    cost_usd DECIMAL(10,6) NOT NULL DEFAULT 0,  -- 6 decimal places for precision
    
    -- Performance metrics
    duration_ms INTEGER,  -- How long the API call took
    
    -- Status
    success BOOLEAN NOT NULL DEFAULT TRUE,
    error_message TEXT,
    error_code TEXT,
    
    -- Request metadata (for debugging)
    request_metadata JSONB,  -- Store additional context if needed
    
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Indexes for fast querying
    CONSTRAINT positive_tokens CHECK (input_tokens >= 0 AND output_tokens >= 0)
);

-- Create indexes for common queries
CREATE INDEX IF NOT EXISTS idx_ai_usage_user_id ON ai_usage_logs(user_id);
CREATE INDEX IF NOT EXISTS idx_ai_usage_created_at ON ai_usage_logs(created_at);
CREATE INDEX IF NOT EXISTS idx_ai_usage_service ON ai_usage_logs(service_name);
CREATE INDEX IF NOT EXISTS idx_ai_usage_provider ON ai_usage_logs(provider);
CREATE INDEX IF NOT EXISTS idx_ai_usage_user_date ON ai_usage_logs(user_id, created_at);
```

---

### STEP 2: Create AI Usage Logging Service

Create file: `backend/app/services/ai_usage_logger.py`
```python
"""
AI Usage Logger Service
Logs all AI API calls with full metadata for cost tracking and analytics.
"""

from datetime import datetime
from decimal import Decimal
from typing import Optional, Dict, Any
import traceback

from backend.app.utils.supabase_client import get_supabase_client

# Pricing per 1M tokens (as of Dec 2024)
PRICING = {
    "anthropic": {
        "claude-3-5-sonnet": {"input": 3.00, "output": 15.00},
        "claude-3-sonnet": {"input": 3.00, "output": 15.00},
        "claude-3-haiku": {"input": 0.25, "output": 1.25},
    },
    "google": {
        "gemini-2.0-flash": {"input": 0.10, "output": 0.40},
        "gemini-1.5-flash": {"input": 0.075, "output": 0.30},
        "gemini-1.5-pro": {"input": 1.25, "output": 5.00},
    },
    "openai": {
        "gpt-4o": {"input": 2.50, "output": 10.00},
        "gpt-4o-mini": {"input": 0.15, "output": 0.60},
    }
}

def calculate_cost(provider: str, model: str, input_tokens: int, output_tokens: int) -> float:
    """Calculate cost in USD based on provider pricing."""
    try:
        # Normalize model name (remove version suffixes if needed)
        model_key = model.lower()
        for key in PRICING.get(provider.lower(), {}):
            if key in model_key or model_key in key:
                pricing = PRICING[provider.lower()][key]
                input_cost = (input_tokens / 1_000_000) * pricing["input"]
                output_cost = (output_tokens / 1_000_000) * pricing["output"]
                return round(input_cost + output_cost, 6)
    except Exception as e:
        print(f"Error calculating cost: {e}")
    
    # Default: estimate based on average pricing
    return round((input_tokens + output_tokens) / 1_000_000 * 2.0, 6)


def log_ai_usage(
    user_id: Optional[str],
    user_email: Optional[str],
    service_name: str,
    service_action: str,
    provider: str,
    model: str,
    input_tokens: int,
    output_tokens: int,
    duration_ms: Optional[int] = None,
    success: bool = True,
    error_message: Optional[str] = None,
    error_code: Optional[str] = None,
    request_metadata: Optional[Dict[str, Any]] = None
) -> bool:
    """
    Log an AI API call to the database.
    
    Returns True if logged successfully, False otherwise.
    """
    try:
        client = get_supabase_client()
        if not client:
            print("ERROR: Could not get Supabase client for AI usage logging")
            return False
        
        total_tokens = input_tokens + output_tokens
        cost_usd = calculate_cost(provider, model, input_tokens, output_tokens)
        
        log_entry = {
            "user_id": user_id,
            "user_email": user_email,
            "service_name": service_name,
            "service_action": service_action,
            "provider": provider,
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "cost_usd": cost_usd,
            "duration_ms": duration_ms,
            "success": success,
            "error_message": error_message,
            "error_code": error_code,
            "request_metadata": request_metadata,
            "created_at": datetime.utcnow().isoformat()
        }
        
        result = client.table("ai_usage_logs").insert(log_entry).execute()
        
        if result.data:
            print(f"✅ AI Usage logged: {service_name}/{service_action} - {total_tokens} tokens, ${cost_usd}")
            return True
        else:
            print(f"❌ Failed to log AI usage: No data returned")
            return False
            
    except Exception as e:
        print(f"❌ Error logging AI usage: {e}")
        traceback.print_exc()
        return False


class AIUsageTracker:
    """
    Context manager for tracking AI usage.
    
    Usage:
        with AIUsageTracker(user_id, user_email, "xray_analyzer", "analyze") as tracker:
            response = call_ai_api(...)
            tracker.set_response(response)
    """
    
    def __init__(
        self,
        user_id: Optional[str],
        user_email: Optional[str],
        service_name: str,
        service_action: str,
        provider: str = "unknown",
        model: str = "unknown"
    ):
        self.user_id = user_id
        self.user_email = user_email
        self.service_name = service_name
        self.service_action = service_action
        self.provider = provider
        self.model = model
        self.start_time = None
        self.input_tokens = 0
        self.output_tokens = 0
        self.success = True
        self.error_message = None
        self.error_code = None
        self.metadata = {}
    
    def __enter__(self):
        self.start_time = datetime.utcnow()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration_ms = None
        if self.start_time:
            duration_ms = int((datetime.utcnow() - self.start_time).total_seconds() * 1000)
        
        if exc_type is not None:
            self.success = False
            self.error_message = str(exc_val)
            self.error_code = exc_type.__name__
        
        log_ai_usage(
            user_id=self.user_id,
            user_email=self.user_email,
            service_name=self.service_name,
            service_action=self.service_action,
            provider=self.provider,
            model=self.model,
            input_tokens=self.input_tokens,
            output_tokens=self.output_tokens,
            duration_ms=duration_ms,
            success=self.success,
            error_message=self.error_message,
            error_code=self.error_code,
            request_metadata=self.metadata if self.metadata else None
        )
        
        return False  # Don't suppress exceptions
    
    def set_response(self, response: Dict[str, Any]):
        """Set token usage from AI response."""
        usage = response.get("usage", {})
        self.input_tokens = usage.get("prompt_tokens", 0) or usage.get("input_tokens", 0)
        self.output_tokens = usage.get("completion_tokens", 0) or usage.get("output_tokens", 0)
        
        # Try to get model from response
        if "model" in response:
            self.model = response["model"]
    
    def set_tokens(self, input_tokens: int, output_tokens: int):
        """Manually set token counts."""
        self.input_tokens = input_tokens
        self.output_tokens = output_tokens
    
    def set_provider_model(self, provider: str, model: str):
        """Set provider and model."""
        self.provider = provider
        self.model = model
    
    def set_error(self, error_message: str, error_code: str = None):
        """Mark as failed with error details."""
        self.success = False
        self.error_message = error_message
        self.error_code = error_code
    
    def add_metadata(self, key: str, value: Any):
        """Add metadata for debugging."""
        self.metadata[key] = value
```

---

### STEP 3: Integrate Logging into AI Services

Find your AI service file (likely `backend/app/services/ai_service.py` or similar).

Add logging to EVERY AI call. Example integration:
```python
from backend.app.services.ai_usage_logger import AIUsageTracker, log_ai_usage

async def call_ai_service(
    user_id: str,
    user_email: str,
    service_name: str,
    prompt: str,
    model: str = "gemini-2.0-flash"
):
    """Example of how to integrate logging into AI calls."""
    
    # Determine provider from model name
    if "gemini" in model.lower():
        provider = "google"
    elif "claude" in model.lower():
        provider = "anthropic"
    elif "gpt" in model.lower():
        provider = "openai"
    else:
        provider = "unknown"
    
    with AIUsageTracker(
        user_id=user_id,
        user_email=user_email,
        service_name=service_name,
        service_action="generate",
        provider=provider,
        model=model
    ) as tracker:
        
        # Make the actual AI API call
        response = await litellm.acompletion(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )
        
        # Extract token usage from response
        if hasattr(response, 'usage'):
            tracker.set_tokens(
                input_tokens=response.usage.prompt_tokens,
                output_tokens=response.usage.completion_tokens
            )
        
        return response
```

---

### STEP 4: Update Existing AI Service Calls

Find ALL places where AI is called and add logging. Common locations:

1. **X-Ray Analyzer** - `backend/app/services/xray_service.py` or similar
2. **CV Optimizer** - `backend/app/services/cv_service.py` or similar
3. **Questions Predictor** - `backend/app/services/questions_service.py` or similar

For each, add the tracker:
```python
# Before (no logging):
response = await litellm.acompletion(model=model, messages=messages)

# After (with logging):
from backend.app.services.ai_usage_logger import log_ai_usage
import time

start_time = time.time()
response = await litellm.acompletion(model=model, messages=messages)
duration_ms = int((time.time() - start_time) * 1000)

# Log the usage
log_ai_usage(
    user_id=current_user.get("id"),
    user_email=current_user.get("email"),
    service_name="xray_analyzer",  # Change per service
    service_action="analyze",
    provider="google" if "gemini" in model else "anthropic",
    model=model,
    input_tokens=response.usage.prompt_tokens,
    output_tokens=response.usage.completion_tokens,
    duration_ms=duration_ms,
    success=True
)
```

---

### STEP 5: Verify Logging Works

After implementing, test by:

1. Go to the app and use X-Ray Analyzer (or any AI feature)
2. Check the database:
```sql
SELECT * FROM ai_usage_logs ORDER BY created_at DESC LIMIT 10;
```

3. Check Admin → AI Usage page - should show data now

---

### STEP 6: Update Admin AI Usage Endpoint

Make sure `/api/admin/ai-usage/summary` returns correct data:
```python
@router.get("/ai-usage/summary")
async def get_ai_usage_summary(
    days: int = 30,
    current_user: dict = Depends(require_admin)
):
    client = get_supabase_client()
    
    # Get date range
    from datetime import datetime, timedelta
    start_date = (datetime.utcnow() - timedelta(days=days)).isoformat()
    
    # Query usage data
    result = client.table("ai_usage_logs")\
        .select("*")\
        .gte("created_at", start_date)\
        .execute()
    
    logs = result.data or []
    
    # Calculate summaries
    total_tokens = sum(log.get("total_tokens", 0) for log in logs)
    total_cost = sum(float(log.get("cost_usd", 0)) for log in logs)
    total_requests = len(logs)
    successful_requests = sum(1 for log in logs if log.get("success"))
    
    # Group by provider
    by_provider = {}
    for log in logs:
        provider = log.get("provider", "unknown")
        if provider not in by_provider:
            by_provider[provider] = {"tokens": 0, "cost": 0, "requests": 0}
        by_provider[provider]["tokens"] += log.get("total_tokens", 0)
        by_provider[provider]["cost"] += float(log.get("cost_usd", 0))
        by_provider[provider]["requests"] += 1
    
    # Group by service
    by_service = {}
    for log in logs:
        service = log.get("service_name", "unknown")
        if service not in by_service:
            by_service[service] = {"tokens": 0, "cost": 0, "requests": 0}
        by_service[service]["tokens"] += log.get("total_tokens", 0)
        by_service[service]["cost"] += float(log.get("cost_usd", 0))
        by_service[service]["requests"] += 1
    
    return {
        "period_days": days,
        "total_tokens": total_tokens,
        "total_cost": round(total_cost, 4),
        "total_requests": total_requests,
        "success_rate": round(successful_requests / total_requests * 100, 1) if total_requests > 0 else 0,
        "by_provider": by_provider,
        "by_service": by_service
    }
```

---

### Summary of Files to Create/Modify:

| File | Action |
|------|--------|
| Database | Run SQL to create/update ai_usage_logs table |
| `backend/app/services/ai_usage_logger.py` | CREATE - new logging service |
| `backend/app/services/ai_service.py` | MODIFY - add logging to AI calls |
| `backend/app/routes/admin.py` | MODIFY - update summary endpoint |
| Any service that calls AI | MODIFY - add logging |

---

### Test Checklist:

After implementation:
- [ ] Use X-Ray Analyzer feature
- [ ] Check database has new row in ai_usage_logs
- [ ] Check Admin → AI Usage shows data
- [ ] Verify token counts are correct
- [ ] Verify cost calculation is correct