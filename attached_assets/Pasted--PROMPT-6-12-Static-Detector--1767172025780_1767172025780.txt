═══════════════════════════════════════════════════════════════════
PROMPT 6#12: Static Detector - High Priority Issues
═══════════════════════════════════════════════════════════════════

⚠️ CRITICAL COMPLIANCE ⚠️
- Execute ONLY instructions below
- Detection uses word lists - no AI
- Same text → Same issues detected

───────────────────────────────────────────────────────────────────

TASK: Create detector for HIGH priority issues

OBJECTIVE:
Detect high-priority issues using word lists and patterns:
- WEAK_ACTION_VERBS
- VAGUE_DESCRIPTION
- BUZZWORD_STUFFING
- NO_ACHIEVEMENTS (bullets without results)

───────────────────────────────────────────────────────────────────

INSTRUCTIONS:

Step 1: CREATE file: backend/common/detection/language_detector.py

Step 2: Add this content:

"""
Language Quality Detector

Detects weak verbs, vague descriptions, and buzzword stuffing.
100% CODE - No AI - Deterministic results.
"""

import re
from typing import List, Dict
from .word_lists import (
    WEAK_VERBS,
    BUZZWORDS,
    VAGUE_WORDS,
    BUZZWORD_THRESHOLD,
    VAGUE_THRESHOLD,
)


def detect_weak_verbs(text: str) -> List[Dict]:
    """
    Detect weak action verbs in text.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of WEAK_ACTION_VERBS issues
    """
    issues = []
    text_lower = text.lower()
    found_verbs = []
    
    for verb in WEAK_VERBS:
        if verb.lower() in text_lower:
            # Find the context (surrounding text)
            pattern = re.compile(
                r'.{0,30}' + re.escape(verb) + r'.{0,30}',
                re.IGNORECASE
            )
            matches = pattern.findall(text)
            
            for match in matches[:2]:  # Limit per verb
                if verb.lower() not in [v.lower() for v in found_verbs]:
                    issues.append({
                        'issue_type': 'WEAK_ACTION_VERBS',
                        'location': 'Experience Section',
                        'description': f'Weak/passive phrase detected: "{verb}"',
                        'current': match.strip(),
                        'suggestion': 'Replace with a strong action verb like: led, achieved, delivered, implemented',
                    })
                    found_verbs.append(verb)
    
    return issues


def detect_vague_language(text: str) -> List[Dict]:
    """
    Detect vague/generic language.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of VAGUE_DESCRIPTION issues
    """
    issues = []
    text_lower = text.lower()
    
    vague_count = 0
    found_words = []
    
    for word in VAGUE_WORDS:
        # Use word boundaries to avoid partial matches
        pattern = re.compile(r'\b' + re.escape(word) + r'\b', re.IGNORECASE)
        matches = pattern.findall(text)
        
        if matches:
            vague_count += len(matches)
            found_words.extend(matches)
    
    if vague_count > VAGUE_THRESHOLD:
        issues.append({
            'issue_type': 'VAGUE_DESCRIPTION',
            'location': 'Throughout CV',
            'description': f'Too many vague words ({vague_count} found): {", ".join(set(found_words)[:5])}',
            'current': ', '.join(set(found_words)),
            'suggestion': 'Replace with specific details and numbers',
        })
    
    return issues


def detect_buzzword_stuffing(text: str) -> List[Dict]:
    """
    Detect excessive buzzword usage.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of BUZZWORD_STUFFING issues
    """
    issues = []
    text_lower = text.lower()
    
    buzzword_count = 0
    found_buzzwords = []
    
    for buzzword in BUZZWORDS:
        pattern = re.compile(r'\b' + re.escape(buzzword) + r'\b', re.IGNORECASE)
        matches = pattern.findall(text)
        
        if matches:
            buzzword_count += len(matches)
            found_buzzwords.append(buzzword)
    
    if buzzword_count > BUZZWORD_THRESHOLD:
        issues.append({
            'issue_type': 'BUZZWORD_STUFFING',
            'location': 'Throughout CV',
            'description': f'Too many buzzwords ({buzzword_count} found): {", ".join(found_buzzwords[:5])}',
            'current': ', '.join(found_buzzwords[:10]),
            'suggestion': 'Replace buzzwords with specific achievements and results',
        })
    
    return issues


def detect_language_issues(text: str) -> List[Dict]:
    """
    Detect all language quality issues.
    
    This is the MAIN function for language analysis.
    100% deterministic - same text → same result.
    
    Args:
        text: Full CV text
        
    Returns:
        List of language issues
    """
    issues = []
    
    issues.extend(detect_weak_verbs(text))
    issues.extend(detect_vague_language(text))
    issues.extend(detect_buzzword_stuffing(text))
    
    return issues

───────────────────────────────────────────────────────────────────

FILES TO CREATE:
- backend/common/detection/language_detector.py

DO NOT TOUCH:
- All other files

───────────────────────────────────────────────────────────────────

WHEN COMPLETE:

Confirm:
□ language_detector.py created
□ detect_weak_verbs uses WEAK_VERBS list
□ detect_vague_language uses VAGUE_WORDS list
□ detect_buzzword_stuffing uses BUZZWORDS list
□ detect_language_issues returns all language issues
□ No Python syntax errors

Type "PROMPT 6#12 COMPLETE - READY FOR 7#12" when done.