═══════════════════════════════════════════════════════════════════
PROMPT 8#12: Static Detector - Low Priority Issues
═══════════════════════════════════════════════════════════════════

⚠️ CRITICAL COMPLIANCE ⚠️
- Execute ONLY instructions below
- Detection uses patterns - no AI
- Same text → Same issues detected

───────────────────────────────────────────────────────────────────

TASK: Create detector for LOW priority issues

OBJECTIVE:
Detect low-priority polish issues:
- OUTDATED_INFO (old dates)
- HEADER_STYLE inconsistency
- REPETITIVE_CONTENT

───────────────────────────────────────────────────────────────────

INSTRUCTIONS:

Step 1: CREATE file: backend/common/detection/polish_detector.py

Step 2: Add this content:

"""
Polish and Minor Issues Detector

Detects minor issues for CV polishing.
100% CODE - No AI - Deterministic results.
"""

import re
from typing import List, Dict
from datetime import datetime
from collections import Counter


def detect_outdated_info(text: str, years_threshold: int = 15) -> List[Dict]:
    """
    Detect potentially outdated information (very old dates).
    
    Args:
        text: Text to analyze
        years_threshold: How many years back is considered outdated
        
    Returns:
        List of OUTDATED_INFO issues
    """
    issues = []
    current_year = datetime.now().year
    cutoff_year = current_year - years_threshold
    
    # Find all year references
    year_pattern = re.compile(r'\b(19\d{2}|20[0-2]\d)\b')
    years = year_pattern.findall(text)
    
    old_years = [y for y in years if int(y) < cutoff_year]
    
    if old_years:
        issues.append({
            'issue_type': 'OUTDATED_INFO',
            'location': 'Throughout CV',
            'description': f'CV contains references to {min(old_years)} - consider removing information older than {years_threshold} years',
            'current': f'Years found: {", ".join(sorted(set(old_years)))}',
            'suggestion': 'Focus on recent experience (last 10-15 years) unless earlier experience is highly relevant',
        })
    
    return issues


def detect_header_inconsistency(text: str) -> List[Dict]:
    """
    Detect inconsistent header capitalization/formatting.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of HEADER_STYLE issues
    """
    issues = []
    
    # Common header words
    header_words = ['experience', 'education', 'skills', 'summary', 'profile', 'objective']
    
    # Check header styles
    styles_found = {
        'uppercase': 0,
        'titlecase': 0,
        'lowercase': 0,
    }
    
    for word in header_words:
        # Uppercase version
        if re.search(r'\b' + word.upper() + r'\b', text):
            styles_found['uppercase'] += 1
        # Title case version
        if re.search(r'\b' + word.title() + r'\b', text):
            styles_found['titlecase'] += 1
        # Lowercase version (less common as header)
        if re.search(r'^\s*' + word + r'\s*$', text, re.MULTILINE | re.IGNORECASE):
            styles_found['lowercase'] += 1
    
    # Count non-zero styles
    active_styles = sum(1 for v in styles_found.values() if v > 0)
    
    if active_styles > 1:
        issues.append({
            'issue_type': 'HEADER_STYLE',
            'location': 'Section Headers',
            'description': 'Inconsistent header capitalization (mix of UPPERCASE and Title Case)',
            'suggestion': 'Use consistent capitalization for all section headers',
        })
    
    return issues


def detect_repetitive_content(text: str) -> List[Dict]:
    """
    Detect repeated phrases or content.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of REPETITIVE_CONTENT issues
    """
    issues = []
    
    # Find repeated phrases (3+ words)
    words = text.lower().split()
    phrases = []
    
    # Extract 3-5 word phrases
    for length in [3, 4, 5]:
        for i in range(len(words) - length + 1):
            phrase = ' '.join(words[i:i + length])
            # Filter out common phrases
            if not any(x in phrase for x in ['and', 'the', 'for', 'with', 'to', 'in', 'of', 'a']):
                phrases.append(phrase)
    
    # Count phrase occurrences
    phrase_counts = Counter(phrases)
    repeated = [(phrase, count) for phrase, count in phrase_counts.items() if count > 1]
    
    if repeated:
        # Get top 3 most repeated
        top_repeated = sorted(repeated, key=lambda x: x[1], reverse=True)[:3]
        
        for phrase, count in top_repeated:
            if count >= 2 and len(phrase.split()) >= 3:
                issues.append({
                    'issue_type': 'REPETITIVE_CONTENT',
                    'location': 'Throughout CV',
                    'description': f'Phrase repeated {count} times: "{phrase}"',
                    'current': phrase,
                    'suggestion': 'Vary your language to avoid repetition',
                })
    
    return issues


def detect_polish_issues(text: str) -> List[Dict]:
    """
    Detect all polish/minor issues.
    
    This is the MAIN function for polish analysis.
    100% deterministic - same text → same result.
    
    Args:
        text: Full CV text
        
    Returns:
        List of polish issues
    """
    issues = []
    
    issues.extend(detect_outdated_info(text))
    issues.extend(detect_header_inconsistency(text))
    issues.extend(detect_repetitive_content(text))
    
    return issues

───────────────────────────────────────────────────────────────────

FILES TO CREATE:
- backend/common/detection/polish_detector.py

DO NOT TOUCH:
- All other files

───────────────────────────────────────────────────────────────────

WHEN COMPLETE:

Confirm:
□ polish_detector.py created
□ detect_outdated_info works
□ detect_header_inconsistency works
□ detect_repetitive_content works
□ No Python syntax errors

Type "PROMPT 8#12 COMPLETE - READY FOR 9#12" when done.